---
layout: post
title: "Web Development"
description: "Course notes from Harvard CS75, Summer 2012."
author: "Nathan Tsai"
toc: true
comments: false
# image: 
hide: false
search_exclude: false
show_tags: true
# sticky_rank: 1
categories: [course-notes, web-development]
permalink: /harvard-cs75
---

# Harvard CS75: Web Development, Summer 2012

## Course Resources
* [Course Website](https://www.cs75.tv)
* Professor: David J. Malan

## 9. Scalability
* [Video Lecture](https://www.youtube.com/watch?v=-W9F__D3oY4)

* Virtual Private Server vs. Shared Web Host
    * VPS divides up an OS using hypervisors to run multiple virtual machines on one physical machine.
    * Shared Web Hosts

* Vertical Scaling
    * Refers to adding more resources (CPU, RAM, disk, etc.) to a machine.
    * However, vertical scaling is expensive limited by the machine's max performance and state-of-the-art technology.

* Horizontal Scaling
    * Refers to adding more machines rather than upgrading a single machine.

* Load Balancing
    * Refers to evenly distributing requests to divide load across all backend machines.
    * Approaches
        * Who's busiest?: The load balancer can check which machines have available resources to handle a new request.
        * Dedicated machines: Machines can also be dedicated to a specific task (e.g. HTML, images, videos, etc.), and the load balancer can decide which machine is appropriate for the request.
            * All machines don't need to store n copies of the same data, which could save space.
        * Round Robin: load balancer chooses the next machine in line, wrapping around to the first machine.
            * However, one server could receive larger requests, continuing to get more requests 1/n of the time using the round robin model.
    * When visiting a website, the OS queries the DNS for the IP associated with the website URL. Then it sends a request to the IP address and receives a response.
        * Caching: Future requests on the same website send requests to the cached IP address, rather than querying the DNS server again. Caching can contribute to uneven loads on certain servers.
        * Time to Live (TTL) values are associated with responses from a DNS server, and these values determine which server you are assigned to.

* Shared Session State
    * Load balancing breaks sessions and cookies.
    * Sessions are specific to a given machine and serving requests from different machines to the same user will not maintain user's session variables.
        * E.g. you might be prompted to log in again
        * E.g. your cart might not be consistent across machines
        * This problem does not occur when using dedicated machines for specific requests, but it is still limited by vertical scaling of a single machine.
    * We can use a shared database or file system that is connected to all servers to hold all the user sessions to solve the problem of shared state.
        * But if this shared database fails, then all sessions are lost.

* Redundant Array of Independent Disks (RAID)
    * **Striping** means writing some data to one drive, then writing some data to another drive.
    * In RAID0, the file is split between both drives.
        * Assuming multiple hard drives (e.g. 2 identical hard drives in RAID0), the machine will **stripe** data across these hard drives.
        * This allows the machine to write data faster because it can write to a new drive while the previous drive is still spinning.
    * In RAID1, the file is mirrored across both hard drives.
        * Files are mirrored to create duplicate copies on both hard drives, allowing for redundancy in case of failures.
    * In RAID5, only 1 of 3+ drives are used for redundancy, and the rest can be used for disk space.
        * Any 1 hard drive can die without losing data.
    * In RAID6, any 2 drives can fail without losing data.

* Shared Storage
    * Sharing files across servers can help maintain consistent sessions.
    * Session data can be stored in a shared database, like MySQL.

* Database Replication
    * How do we solve the single point of failure problem of a file server going down?
    * Replication: maintain a synchronized copy of the data on another machine.

* Session Affinity
    * Sticky Sessions: even if you visit a website multiple time, you will end up on the same backend server.
    * Cookies can store the ID of the server to help users maintain the same session and same server.
        * However, if cookie data changes or should be private, the cookie may be inappropriate.
        * We just store a large random number in the cookie generated by the load balancer and have the load balancer use that number to determine which server to send the request to.

* PHP Acceleration
    * Run PHP source code through an executable program to "compile" into more efficient opcodes.
    * PHP usually discards the opcodes after every run, but we can cache the opcodes to handle duplicate requests efficiently.

* In-Memory Caching
    * Craiglist converts product listings into HTML files, rather than storing the data in a database and generating product listings dynamically.
        * The cached HTML files can avoid re-generating the same product listings.
        * Serving static content is faster than generating dynamic content.
        * However, storing static HTML files may not be space efficient.
        * Also, applying any updates across all the pages is extremely tedious.
    * MySQL Query Cache
        * Setting `query_cache_type = 1` allows caching of results for identically executed queries.
    * Memcached
        * Memory caching software to run on either the same or different server that stores things in RAM.
        * Connect to the Memcached server, get something from the cache (cache hit), i.e. user data.
        * If the user is `NULL` and doesn't exist in the cache (cache miss), query the database and cache the results.
    * When the cache gets too full, we need to utilize **cache eviction** to reclaim space.
        * Least Recently Used (LRU): evicts the data that has not been used the longest.

* Storage Engines
    * MyISAM: uses full-table locks
    * Memory/Heap: tables entirely stored in RAM
    * Archive: tables compressed by default
    * InnoDB: default engine, supports transactions 
    * NDB: network storage for clustering

* Data Replication
    * Active-Passive: active node and passive nodes are identical
        * Any query executed on the active node is replicated to one or more passive nodes.
        * Passive nodes add redundancy and can handle read-heavy workloads.
        * E.g. Facebook's read-heavy workload is ideal for this type of data replication
    * However, only writing to the active node is a single point of failure for writes.

    * Active-Active: two active nodes, each has its own passive nodes
        * Queries can be written to any active node and are replicated to the other active node.
        * The active nodes are then replicated by passive nodes.
        * Active nodes can load balance write operations and handle writes when one active node is offline.

* Load Balancing & Replication
    * Requests from the network goes through load balancer to the web servers.
    * The web servers direct read/write queries to another load balancer to the database nodes.
    * The read queries are directed to passive nodes and the write queries are directed to active nodes.
    * Active-Active: a pair of load balancers can both receive requests to backend servers
    * The load balancers send continuous heartbeats to each other determine status of other load balancer.
    * Active-Passive: if the active load balancer goes offline, the passive load balancer promotes itself and handles both requests through both IP addresses.

* Partitioning
    * Partitioning refers to dividing servers into multiple partitions.
        * E.g. School-specific Facebook servers
        * E.g. Dividing up users by A-M and N-Z names.
    * We can balance load based on some high-level user information.
    * Using a load balancer for each partition to send requests to a corresponding partition of servers.

* High Availability
    * Refers to relations between 2+ servers that are checking each other's health to maintain service at all times.

* Data Center Redundancy
    * To process a lot of requests across multiple web servers, we need to use a load balancer.
    * To maintain sticky sessions, we can use cookies generated by the load balancer.
    * To ensure the persistent data is consistent across all servers, we can add a shared database.
    * To ensure the shared database is not a single point of failure, we can use active-active databases.
    * To connect all web servers to all database server, we can use a load balancer to handle distributing web server requests to the database servers.
    * To ensure the load balancer is not a single point of failure, we can use active-active load balancers.
    * To connect all the servers together, we can use multiple switches for connections with redundancy.
    * To handle the case if the data center building burns down, we can duplicate everything across multiple data centers around the world.
    * We can apply load balancing at the DNS level to balance loads across data centers.

* Security
    * What type of traffic should be coming into the data center for a web server?
        * Limit connections to TCP Port 80, SSL Port 443, SSH Port 22, etc.
    * What type of traffic goes from load balancers to web servers?
        * Offload SSL encryption at load balancers and just use TCP Port 80.
    * What type of traffic goes from web servers to databases?
        * TCP Port 3306 (MySQL queries, i.e. Select, Insert, Delete, Update)
    * We restrict the traffic at every tier to avoid any potential problems or unexpected behavior, whether it's in or out.


## References
[^1]: Footnote